{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# RSNA 2024 Deep Learning Lab\n",
        "\n",
        "# https://tinyurl.com/c43js5va\n",
        "\n",
        "## December 3, 2024\n",
        "## Authors: Ian Pan, MD; Felipe Kitamura, MD, PhD\n",
        "\n",
        "## Objectives:\n",
        "*   Train a simple deep learning to predict bone age from pediatric hand radiographs\n",
        "*   Deploy the model using Gradio and Hugging Face\n",
        "\n",
        "## Prerequisites:\n",
        "*   Basic Python programming using standard libraries (e.g., NumPy, Pandas) and the PyTorch deep learning library\n",
        "*   Basic understanding of convolutional neural networks and deep learning\n",
        "\n",
        "## Let's get started!\n",
        "\n"
      ],
      "metadata": {
        "id": "D0WkTERmZ4mj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install Packages"
      ],
      "metadata": {
        "id": "dLz-fivZe2m5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -qq install lightning gradio"
      ],
      "metadata": {
        "id": "1lOB2OfFe3qK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Modules"
      ],
      "metadata": {
        "id": "IYH0vzKPdycP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import albumentations as A\n",
        "import cv2\n",
        "import kagglehub\n",
        "import lightning\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import timm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "metadata": {
        "id": "7PH259pvdxvf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download Data\n",
        "\n",
        "This dataset contains a subset of 1,200 images from the RSNA Pediatric Bone Age Challenge. The images are downsampled to half their original resolutions to further decrease the size of the dataset for this demonstration. Learn more about the challenge here: https://www.rsna.org/rsnai/ai-image-challenge/rsna-pediatric-bone-age-challenge-2017"
      ],
      "metadata": {
        "id": "NgFo321ucfQL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = kagglehub.dataset_download(\"vaillant/rsna-pediatric-bone-age-challenge-n1200\")\n",
        "print(f\"Dataset saved to: {path}\")"
      ],
      "metadata": {
        "id": "Nah4cBCjc8Ti"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install Packages"
      ],
      "metadata": {
        "id": "PHAdPodpZmf6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Explore Data\n",
        "\n",
        "Note that the original bone age labels are in units of months. We will convert them to years."
      ],
      "metadata": {
        "id": "TX9p7EtpZySf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(os.path.join(path, \"train.csv\"))\n",
        "df[\"bone_age\"] = df.bone_age / 12.\n",
        "df[\"filepath\"] = df.pid.apply(lambda x: os.path.join(path, \"images\", f\"{x}.png\"))\n",
        "df.head()"
      ],
      "metadata": {
        "id": "QmV26XAmZvuB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.female.value_counts()"
      ],
      "metadata": {
        "id": "pCxQDXjxZMDf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.bone_age.describe()"
      ],
      "metadata": {
        "id": "GL6XeWJWZl31"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample = np.random.choice(df.filepath, 4, replace=False)\n",
        "for idx, samp in enumerate(sample):\n",
        "  img = cv2.imread(samp, 0)\n",
        "  plt.subplot(2, 2, idx + 1)\n",
        "  plt.imshow(img, cmap=\"gray\")\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5ixlzVsOZdQE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Training, Validation, and Test Sets"
      ],
      "metadata": {
        "id": "HJC0UNTMhiB-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_val_test_split(df, train_pct, test_pct):\n",
        "  n_train = int(len(df) * train_pct)\n",
        "  n_test = int(len(df) * test_pct)\n",
        "  n_val = len(df) - n_train - n_test\n",
        "  print(f\"TRAIN : n={n_train} {train_pct*100:0.1f}%\")\n",
        "  print(f\"VAL   : n={n_val} {(1-train_pct-test_pct)*100:0.1f}%\")\n",
        "  print(f\"TEST  : n={n_test} {test_pct*100:0.1f}%\")\n",
        "  all_indices = np.arange(len(df), dtype=np.int64)\n",
        "  train_indices = np.random.choice(all_indices, n_train, replace=False)\n",
        "  not_train_indices = list(set(all_indices) - set(train_indices))\n",
        "  test_indices = np.random.choice(not_train_indices, n_test, replace=False)\n",
        "  val_indices = list(set(not_train_indices) - set(test_indices))\n",
        "  return df.iloc[train_indices], df.iloc[val_indices], df.iloc[test_indices]\n",
        "\n",
        "\n",
        "train_df, val_df, test_df = train_val_test_split(df, train_pct=0.7, test_pct=0.2)"
      ],
      "metadata": {
        "id": "jgkMfrOThmo5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create a PyTorch Datasets and Data Loaders"
      ],
      "metadata": {
        "id": "e1-rn3Qdgfh-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BoneAgeDataset(Dataset):\n",
        "\n",
        "  def __init__(self,\n",
        "               filepaths,\n",
        "               labels,\n",
        "               female,\n",
        "               transforms=None):\n",
        "    self.filepaths = filepaths\n",
        "    self.labels = labels\n",
        "    self.female = female\n",
        "    self.transforms = transforms\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.filepaths)\n",
        "\n",
        "  def __getitem__(self, i):\n",
        "    img = cv2.imread(self.filepaths[i], 0)\n",
        "    label = self.labels[i]\n",
        "\n",
        "    if self.transforms:\n",
        "      img = self.transforms(image=img)[\"image\"]\n",
        "\n",
        "    img = torch.from_numpy(img).float()\n",
        "    # simple normalization from 8-bit [0, 255] -> float [0, 1]\n",
        "    img = img / 255.\n",
        "    img = img.unsqueeze(0) # add channel dimension H, W -> C, H, W\n",
        "\n",
        "    return {\"x\": img, \"y\": torch.Tensor([label]), \"female\": torch.tensor(self.female[i])}\n"
      ],
      "metadata": {
        "id": "bSB2Hr7Kf3ml"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Specify the image dimensions and batch size here. Larger image dimensions and batch size require more GPU memory. While increasing image size can often lead to improved performance (up to a certain point), training and inference times will also be increased, and batch sizes will need to be decreased accordingly."
      ],
      "metadata": {
        "id": "TQ5djAywkl8E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGE_HEIGHT, IMAGE_WIDTH = 512, 512\n",
        "BATCH_SIZE = 16"
      ],
      "metadata": {
        "id": "sgdhcXo9jzvC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_transforms = A.Compose([\n",
        "    A.Resize(IMAGE_HEIGHT, IMAGE_WIDTH, p=1),\n",
        "    A.HorizontalFlip(p=0.5)\n",
        "])\n",
        "\n",
        "val_transforms = A.Compose([\n",
        "    A.Resize(IMAGE_HEIGHT, IMAGE_WIDTH, p=1)\n",
        "])\n",
        "\n",
        "train_dataset = BoneAgeDataset(filepaths=train_df.filepath.values,\n",
        "                               labels=train_df.bone_age.values,\n",
        "                               female=train_df.female.values,\n",
        "                               transforms=train_transforms)\n",
        "\n",
        "val_dataset = BoneAgeDataset(filepaths=val_df.filepath.values,\n",
        "                             labels=val_df.bone_age.values,\n",
        "                             female=val_df.female.values,\n",
        "                             transforms=val_transforms)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True, num_workers=2, pin_memory=True, persistent_workers=True)\n",
        "\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE * 2, shuffle=False, drop_last=False, num_workers=2, pin_memory=True, persistent_workers=True)"
      ],
      "metadata": {
        "id": "AVmDH4BehaK6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Your Model\n",
        "\n",
        "The PyTorch Image Models library (https://github.com/huggingface/pytorch-image-models) has an extensive selection of neural nets, including convolutional neural nets and transformers, with pretrained weights.\n",
        "\n",
        "Because our radiographs are grayscale, we must specify the number of input channels as 1 (`in_chans=1`). We are predicting bone age as a regression tasks, so we will also specify `num_classes=1`.\n",
        "\n",
        "To avoid writing too much training code from scratch, we will be using PyTorch Lightning (https://lightning.ai)."
      ],
      "metadata": {
        "id": "XCcEAL_8lHre"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BoneAgeModel(lightning.LightningModule):\n",
        "\n",
        "  def __init__(self, net, optimizer, scheduler, loss_fn):\n",
        "    super().__init__()\n",
        "    self.net = net\n",
        "    self.optimizer = optimizer\n",
        "    self.scheduler = scheduler\n",
        "    self.loss_fn = loss_fn\n",
        "\n",
        "    self.val_losses = []\n",
        "\n",
        "  def training_step(self, batch, batch_index):\n",
        "    out = self.net(batch[\"x\"])\n",
        "    loss = self.loss_fn(out, batch[\"y\"])\n",
        "    return loss\n",
        "\n",
        "  def validation_step(self, batch, batch_index):\n",
        "    out = self.net(batch[\"x\"])\n",
        "    loss = self.loss_fn(out, batch[\"y\"])\n",
        "    self.val_losses.append(loss.item())\n",
        "\n",
        "  def on_validation_epoch_end(self, *args, **kwargs):\n",
        "    val_loss = np.mean(self.val_losses)\n",
        "    self.val_losses = []\n",
        "    print(f\"Validation Loss : {val_loss:0.3f}\")\n",
        "\n",
        "  def configure_optimizers(self):\n",
        "    lr_scheduler = {\"scheduler\": self.scheduler, \"interval\": \"step\"}\n",
        "    return {\"optimizer\": self.optimizer, \"lr_scheduler\": lr_scheduler}"
      ],
      "metadata": {
        "id": "dqjhri37nJus"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BACKBONE = \"resnet18d\"\n",
        "LEARNING_RATE = 3e-4\n",
        "NUM_EPOCHS = 10\n",
        "\n",
        "net = timm.create_model(BACKBONE, pretrained=True, in_chans=1, num_classes=1)\n",
        "optimizer = torch.optim.AdamW(net.parameters(), LEARNING_RATE)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer,\n",
        "                                                       T_max=NUM_EPOCHS * len(train_loader),\n",
        "                                                       eta_min=0.0)\n",
        "loss_fn = nn.L1Loss() # equivalent to mean absolute error\n",
        "\n",
        "model = BoneAgeModel(net, optimizer, scheduler, loss_fn)"
      ],
      "metadata": {
        "id": "Q8Ifot-elHXZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train Model"
      ],
      "metadata": {
        "id": "eWIueCE7nvyq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = [\n",
        "  lightning.pytorch.callbacks.ModelCheckpoint(\n",
        "    dirpath=\"./checkpoints/\",\n",
        "    filename=\"{epoch:03d}\",\n",
        "    save_last=True,\n",
        "    save_weights_only=True,\n",
        "    save_top_k=1\n",
        "  )\n",
        "]\n",
        "\n",
        "\n",
        "trainer = lightning.Trainer(max_epochs=NUM_EPOCHS, check_val_every_n_epoch=2, callbacks=callbacks)\n",
        "trainer.fit(model, train_loader, val_loader)"
      ],
      "metadata": {
        "id": "ab4xzDpunxr6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Trained model weights saved to : {trainer.callbacks[-1].best_model_path}\")"
      ],
      "metadata": {
        "id": "kEAzplN2x2Ag"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Your Demo Using Gradio"
      ],
      "metadata": {
        "id": "FIUIy4gdwSa7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/checkpoints/epoch=009.ckpt /content/epoch=009.ckpt"
      ],
      "metadata": {
        "id": "KAnMaSvYrbf0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import lightning\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import timm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "BACKBONE = \"resnet18d\"\n",
        "IMAGE_HEIGHT, IMAGE_WIDTH = 512, 512\n",
        "\n",
        "trained_weights_path = \"epoch=009.ckpt\"\n",
        "trained_weights = torch.load(trained_weights_path, map_location=torch.device('cpu'))[\"state_dict\"]\n",
        "\n",
        "# recreate the model\n",
        "class BoneAgeModel(lightning.LightningModule):\n",
        "\n",
        "  def __init__(self, net, optimizer, scheduler, loss_fn):\n",
        "    super().__init__()\n",
        "    self.net = net\n",
        "    self.optimizer = optimizer\n",
        "    self.scheduler = scheduler\n",
        "    self.loss_fn = loss_fn\n",
        "\n",
        "    self.val_losses = []\n",
        "\n",
        "  def training_step(self, batch, batch_index):\n",
        "    out = self.net(batch[\"x\"])\n",
        "    loss = self.loss_fn(out, batch[\"y\"])\n",
        "    return loss\n",
        "\n",
        "  def validation_step(self, batch, batch_index):\n",
        "    out = self.net(batch[\"x\"])\n",
        "    loss = self.loss_fn(out, batch[\"y\"])\n",
        "    self.val_losses.append(loss.item())\n",
        "\n",
        "  def on_validation_epoch_end(self, *args, **kwargs):\n",
        "    val_loss = np.mean(self.val_losses)\n",
        "    self.val_losses = []\n",
        "    print(f\"Validation Loss : {val_loss:0.3f}\")\n",
        "\n",
        "  def configure_optimizers(self):\n",
        "    lr_scheduler = {\"scheduler\": self.scheduler, \"interval\": \"step\"}\n",
        "    return {\"optimizer\": self.optimizer, \"lr_scheduler\": lr_scheduler}\n",
        "\n",
        "net = timm.create_model(BACKBONE, pretrained=True, in_chans=1, num_classes=1)\n",
        "trained_model = BoneAgeModel(net, None, None, None)\n",
        "trained_model.load_state_dict(trained_weights)\n",
        "trained_model.eval()\n",
        "\n",
        "\n",
        "def predict_bone_age(Radiograph):\n",
        "  img = torch.from_numpy(Radiograph)\n",
        "  img = img.unsqueeze(0).unsqueeze(0) # add channel and batch dimensions\n",
        "  img = img / 255. # use same normalization as in the PyTorch dataset\n",
        "  with torch.inference_mode():\n",
        "    bone_age = trained_model.net(img)[0].item()\n",
        "  years = int(bone_age)\n",
        "  months = round((bone_age - years) * 12)\n",
        "  return f\"Predicted Bone Age: {years} years, {months} months\"\n",
        "\n",
        "\n",
        "image = gr.Image(height=IMAGE_HEIGHT, width=IMAGE_WIDTH, image_mode=\"L\") # L for grayscale\n",
        "label = gr.Label(show_label=True, label=\"Bone Age Prediction\")\n",
        "\n",
        "demo = gr.Interface(fn=predict_bone_age,\n",
        "                    inputs=[image],\n",
        "                    outputs=label)\n",
        "\n",
        "demo.launch(debug=True)"
      ],
      "metadata": {
        "id": "ZCvkMpyhRNpt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To deploy the gradio interface as a separate website, you will need a requirements.txt with the following content:\n",
        "\n",
        "\n",
        "```\n",
        "lightning\n",
        "gradio\n",
        "timm\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "yqliF5tOVwN7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A few things to note:\n",
        "*   The image input box shows \"Radiograph\" in the top left corner, which corresponds to the name of the argument in the `predict_bone_age` function which was passed to `gr.Interface`.\n",
        "*   We use `gr.Label` as our output because we are not displaying any images or videos, just the bone age prediction as a string. If we wanted to display an image, we could use `gr.Image`.\n",
        "*   Though we only provided 1 input, note that this was passed as a list to `gr.Interface` and thus multiple inputs can be provided (see bonus section below).\n",
        "\n"
      ],
      "metadata": {
        "id": "h2HPoIN2Urco"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Bonus:**"
      ],
      "metadata": {
        "id": "Je3FP8Bav71P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Improve Performance by Incorporating Patient Sex\n",
        "\n",
        "Image classification can be oversimplified into 2 steps: feature extraction followed by linear classification (or regression).\n",
        "\n",
        "The neural net is doing the bulk of the work by essentially compressing the original high-dimensional output into a 1-dimensional vector. The final linear layer then maps this vector to predict whatever target you have specified.\n",
        "\n",
        "Bone age depends on the sex of the patient, and thus this information will likely be useful for the model to have.\n",
        "\n",
        "Here, we add on the patient sex to the 1-dimensional feature vector by passing the binary value (female or not) through an embedding layer (a glorified lookup table) before the final regression step through the linear layer."
      ],
      "metadata": {
        "id": "O32p8qunsK4s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "\n",
        "  def __init__(self, backbone):\n",
        "    super().__init__()\n",
        "    self.backbone = timm.create_model(backbone, pretrained=True, in_chans=1, num_classes=0)\n",
        "    dim_feats = self.backbone(torch.randn((2, 1, 64, 64))).size(1)\n",
        "    self.embed = nn.Embedding(2, 32)\n",
        "    self.regressor = nn.Linear(dim_feats + 32, 1)\n",
        "\n",
        "  def forward(self, x, female):\n",
        "    feat = self.backbone(x)\n",
        "    feat = torch.cat([feat, self.embed(female.long())], dim=1)\n",
        "    return self.regressor(feat)\n",
        "\n",
        "\n",
        "class BoneAgeModelV2(BoneAgeModel):\n",
        "\n",
        "  def training_step(self, batch, batch_index):\n",
        "    out = self.net(batch[\"x\"], batch[\"female\"])\n",
        "    loss = self.loss_fn(out, batch[\"y\"])\n",
        "    return loss\n",
        "\n",
        "  def validation_step(self, batch, batch_index):\n",
        "    out = self.net(batch[\"x\"], batch[\"female\"])\n",
        "    loss = self.loss_fn(out, batch[\"y\"])\n",
        "    self.val_losses.append(loss.item())"
      ],
      "metadata": {
        "id": "I4MNAUXxkabO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = Net(BACKBONE)\n",
        "optimizer = torch.optim.AdamW(net.parameters(), LEARNING_RATE)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer,\n",
        "                                                       T_max=NUM_EPOCHS * len(train_loader),\n",
        "                                                       eta_min=0.0)\n",
        "loss_fn = nn.L1Loss()\n",
        "\n",
        "model = BoneAgeModelV2(net, optimizer, scheduler, loss_fn)\n",
        "\n",
        "trainer = lightning.Trainer(max_epochs=NUM_EPOCHS)\n",
        "trainer.fit(model, train_loader, val_loader)"
      ],
      "metadata": {
        "id": "5zjf4tFwl_GW",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Trained model weights saved to : {trainer.callbacks[-1].best_model_path}\")\n",
        "!cp {trainer.callbacks[-1].best_model_path} /content/{trainer.callbacks[-1].best_model_path.split(\"/\")[-1]}"
      ],
      "metadata": {
        "id": "y-IGuUnaW0Wq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import lightning\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import timm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "BACKBONE = \"resnet18d\"\n",
        "IMAGE_HEIGHT, IMAGE_WIDTH = 512, 512\n",
        "\n",
        "trained_weights_path = \"epoch=9-step=520.ckpt\"\n",
        "trained_weights = torch.load(trained_weights_path, map_location=torch.device('cpu'))[\"state_dict\"]\n",
        "\n",
        "# recreate the model\n",
        "\n",
        "class Net(nn.Module):\n",
        "\n",
        "  def __init__(self, backbone):\n",
        "    super().__init__()\n",
        "    self.backbone = timm.create_model(backbone, pretrained=True, in_chans=1, num_classes=0)\n",
        "    dim_feats = self.backbone(torch.randn((2, 1, 64, 64))).size(1)\n",
        "    self.embed = nn.Embedding(2, 32)\n",
        "    self.regressor = nn.Linear(dim_feats + 32, 1)\n",
        "\n",
        "  def forward(self, x, female):\n",
        "    feat = self.backbone(x)\n",
        "    feat = torch.cat([feat, self.embed(female.long())], dim=1)\n",
        "    return self.regressor(feat)\n",
        "\n",
        "class BoneAgeModel(lightning.LightningModule):\n",
        "\n",
        "  def __init__(self, net, optimizer, scheduler, loss_fn):\n",
        "    super().__init__()\n",
        "    self.net = net\n",
        "    self.optimizer = optimizer\n",
        "    self.scheduler = scheduler\n",
        "    self.loss_fn = loss_fn\n",
        "\n",
        "    self.val_losses = []\n",
        "\n",
        "  def training_step(self, batch, batch_index):\n",
        "    out = self.net(batch[\"x\"])\n",
        "    loss = self.loss_fn(out, batch[\"y\"])\n",
        "    return loss\n",
        "\n",
        "  def validation_step(self, batch, batch_index):\n",
        "    out = self.net(batch[\"x\"])\n",
        "    loss = self.loss_fn(out, batch[\"y\"])\n",
        "    self.val_losses.append(loss.item())\n",
        "\n",
        "  def on_validation_epoch_end(self, *args, **kwargs):\n",
        "    val_loss = np.mean(self.val_losses)\n",
        "    self.val_losses = []\n",
        "    print(f\"Validation Loss : {val_loss:0.3f}\")\n",
        "\n",
        "  def configure_optimizers(self):\n",
        "    lr_scheduler = {\"scheduler\": self.scheduler, \"interval\": \"step\"}\n",
        "    return {\"optimizer\": self.optimizer, \"lr_scheduler\": lr_scheduler}\n",
        "\n",
        "class BoneAgeModelV2(BoneAgeModel):\n",
        "\n",
        "  def training_step(self, batch, batch_index):\n",
        "    out = self.net(batch[\"x\"], batch[\"female\"])\n",
        "    loss = self.loss_fn(out, batch[\"y\"])\n",
        "    return loss\n",
        "\n",
        "  def validation_step(self, batch, batch_index):\n",
        "    out = self.net(batch[\"x\"], batch[\"female\"])\n",
        "    loss = self.loss_fn(out, batch[\"y\"])\n",
        "    self.val_losses.append(loss.item())\n",
        "\n",
        "\n",
        "net = Net(BACKBONE)\n",
        "trained_model = BoneAgeModelV2(net, None, None, None)\n",
        "trained_model.load_state_dict(trained_weights)\n",
        "trained_model.eval()\n",
        "\n",
        "\n",
        "def predict_bone_age(Radiograph, Sex):\n",
        "  img = torch.from_numpy(Radiograph)\n",
        "  img = img.unsqueeze(0).unsqueeze(0) # add channel and batch dimensions\n",
        "  img = img / 255. # use same normalization as in the PyTorch dataset\n",
        "  binary_sex = torch.tensor(Sex == \"Female\").unsqueeze(0)\n",
        "  with torch.inference_mode():\n",
        "    bone_age = trained_model.net(img, binary_sex)[0].item()\n",
        "  years = int(bone_age)\n",
        "  months = round((bone_age - years) * 12)\n",
        "  return f\"Predicted Bone Age: {years} years, {months} months\"\n",
        "\n",
        "\n",
        "image = gr.Image(height=IMAGE_HEIGHT, width=IMAGE_WIDTH, image_mode=\"L\") # L for grayscale\n",
        "# additional input\n",
        "sex = gr.Radio([\"Male\", \"Female\"], type=\"index\")\n",
        "label = gr.Label(show_label=True, label=\"Bone Age Prediction\")\n",
        "\n",
        "demo = gr.Interface(fn=predict_bone_age,\n",
        "                    inputs=[image, sex], # <- adding sex as an input\n",
        "                    outputs=label)\n",
        "\n",
        "demo.launch(debug=True)"
      ],
      "metadata": {
        "id": "gQdgktZEntyD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Bonus 2: Deploy on HuggingFace Spaces\n",
        "\n",
        "[Instructions here.](https://scribehow.com/shared/Create_and_Deploy_a_Model_on_Hugging_Face__1JLjq96aRGqyqf1N3O7Yjg)\n"
      ],
      "metadata": {
        "id": "LpZv81RTu54j"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tFoTeKuXvCRp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}